{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Sentiment Analysis - Data Exploration
",
    "
",
    "This notebook explores the Amazon review dataset from Kaggle to understand its characteristics and prepare it for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd
",
    "import numpy as np
",
    "import matplotlib.pyplot as plt
",
    "import seaborn as sns
",
    "from wordcloud import WordCloud
",
    "import re
",
    "from collections import Counter
",
    "
",
    "# Set style for plots
",
    "sns.set(style="whitegrid")
",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your data file
",
    "data_path = '../data/train.csv'
",
    "
",
    "# Load the data
",
    "try:
",
    "    df = pd.read_csv(data_path)
",
    "    print(f"Data loaded successfully! Shape: {df.shape}")
",
    "except Exception as e:
",
    "    print(f"Error loading data: {e}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows
",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe
",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics
",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values
",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rating distribution
",
    "plt.figure(figsize=(10, 6))
",
    "rating_counts = df['Score'].value_counts().sort_index()
",
    "sns.barplot(x=rating_counts.index, y=rating_counts.values)
",
    "plt.title('Distribution of Ratings', fontsize=16)
",
    "plt.xlabel('Rating', fontsize=12)
",
    "plt.ylabel('Count', fontsize=12)
",
    "
",
    "# Add count labels on bars
",
    "for i, count in enumerate(rating_counts.values):
",
    "    plt.text(i, count + 0.1 * max(rating_counts.values), str(count), 
",
    "             ha='center', fontsize=12)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length
",
    "df['text_length'] = df['Text'].apply(lambda x: len(str(x).split()))
",
    "
",
    "# Plot text length distribution
",
    "plt.figure(figsize=(10, 6))
",
    "sns.histplot(df['text_length'], bins=50, kde=True)
",
    "plt.title('Distribution of Review Text Length', fontsize=16)
",
    "plt.xlabel('Text Length (Number of Words)', fontsize=12)
",
    "plt.ylabel('Frequency', fontsize=12)
",
    "plt.xlim(0, 500)  # Limit x-axis for better visualization
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud for All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reviews
",
    "all_text = ' '.join(df['Text'].dropna().astype(str))
",
    "
",
    "# Generate word cloud
",
    "wordcloud = WordCloud(width=800, height=600, background_color='white',
",
    "                      max_words=100, contour_width=3, 
",
    "                      contour_color='steelblue').generate(all_text)
",
    "
",
    "# Display the word cloud
",
    "plt.figure(figsize=(12, 8))
",
    "plt.imshow(wordcloud, interpolation='bilinear')
",
    "plt.axis('off')
",
    "plt.title('Word Cloud of All Reviews', fontsize=16)
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for different ratings
",
    "ratings = sorted(df['Score'].unique())
",
    "
",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))
",
    "axes = axes.flatten()
",
    "
",
    "for i, rating in enumerate(ratings):
",
    "    # Filter reviews by rating
",
    "    rating_text = ' '.join(df[df['Score'] == rating]['Text'].dropna().astype(str))
",
    "    
",
    "    # Generate word cloud
",
    "    wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                          max_words=50, contour_width=2, 
",
    "                          contour_color='steelblue').generate(rating_text)
",
    "    
",
    "    # Display the word cloud
",
    "    axes[i].imshow(wordcloud, interpolation='bilinear')
",
    "    axes[i].axis('off')
",
    "    axes[i].set_title(f'Rating {rating} Stars', fontsize=14)
",
    "
",
    "# Hide the last subplot if there are less than 6 ratings
",
    "if len(ratings) < 6:
",
    "    axes[-1].axis('off')
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and count words
",
    "all_words = ' '.join(df['Text'].dropna().astype(str)).lower().split()
",
    "word_counts = Counter(all_words)
",
    "
",
    "# Get most common words
",
    "most_common_words = word_counts.most_common(20)
",
    "
",
    "# Create dataframe for plotting
",
    "df_words = pd.DataFrame(most_common_words, columns=['Word', 'Count'])
",
    "
",
    "# Plot most common words
",
    "plt.figure(figsize=(12, 8))
",
    "sns.barplot(x='Count', y='Word', data=df_words)
",
    "plt.title('Most Common Words in Reviews', fontsize=16)
",
    "plt.xlabel('Count', fontsize=12)
",
    "plt.ylabel('Word', fontsize=12)
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment labels based on rating
",
    "# 1-2 stars: Negative, 3 stars: Neutral, 4-5 stars: Positive
",
    "df['sentiment'] = df['Score'].apply(
",
    "    lambda x: 'negative' if x <= 2 else ('neutral' if x == 3 else 'positive')
",
    ")
",
    "
",
    "# Filter out neutral reviews for binary classification
",
    "df_binary = df[df['sentiment'] != 'neutral'].copy()
",
    "
",
    "# Convert sentiment to binary (0 for negative, 1 for positive)
",
    "df_binary['sentiment_binary'] = df_binary['sentiment'].apply(
",
    "    lambda x: 0 if x == 'negative' else 1
",
    ")
",
    "
",
    "print(f"Original dataset shape: {df.shape}")
",
    "print(f"Binary sentiment dataset shape: {df_binary.shape}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution
",
    "plt.figure(figsize=(10, 6))
",
    "sentiment_counts = df_binary['sentiment'].value_counts()
",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)
",
    "plt.title('Distribution of Sentiments', fontsize=16)
",
    "plt.xlabel('Sentiment', fontsize=12)
",
    "plt.ylabel('Count', fontsize=12)
",
    "
",
    "# Add count labels on bars
",
    "for i, count in enumerate(sentiment_counts.values):
",
    "    plt.text(i, count + 0.1 * max(sentiment_counts.values), str(count), 
",
    "             ha='center', fontsize=12)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab of rating and sentiment
",
    "rating_sentiment = pd.crosstab(df_binary['Score'], df_binary['sentiment'])
",
    "
",
    "# Normalize to get proportions
",
    "rating_sentiment_prop = rating_sentiment.div(rating_sentiment.sum(axis=1), axis=0)
",
    "
",
    "# Plot stacked bar chart
",
    "plt.figure(figsize=(10, 6))
",
    "rating_sentiment_prop.plot(kind='bar', stacked=True, color=['#FF9999', '#66B2FF'])
",
    "plt.title('Sentiment Distribution by Rating', fontsize=16)
",
    "plt.xlabel('Rating', fontsize=12)
",
    "plt.ylabel('Proportion', fontsize=12)
",
    "plt.legend(title='Sentiment')
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for positive and negative reviews
",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))
",
    "
",
    "# Positive reviews word cloud
",
    "positive_text = ' '.join(df_binary[df_binary['sentiment'] == 'positive']['Text'].dropna().astype(str))
",
    "positive_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(positive_text)
",
    "
",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')
",
    "axes[0].axis('off')
",
    "axes[0].set_title('Positive Reviews', fontsize=16)
",
    "
",
    "# Negative reviews word cloud
",
    "negative_text = ' '.join(df_binary[df_binary['sentiment'] == 'negative']['Text'].dropna().astype(str))
",
    "negative_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(negative_text)
",
    "
",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')
",
    "axes[1].axis('off')
",
    "axes[1].set_title('Negative Reviews', fontsize=16)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK for text preprocessing
",
    "import nltk
",
    "from nltk.corpus import stopwords
",
    "from nltk.stem import WordNetLemmatizer
",
    "from nltk.tokenize import word_tokenize
",
    "
",
    "# Download NLTK resources if needed
",
    "try:
",
    "    stopwords.words('english')
",
    "except LookupError:
",
    "    nltk.download('stopwords')
",
    "
",
    "try:
",
    "    nltk.data.find('tokenizers/punkt')
",
    "except LookupError:
",
    "    nltk.download('punkt')
",
    "
",
    "try:
",
    "    nltk.data.find('corpora/wordnet')
",
    "except LookupError:
",
    "    nltk.download('wordnet')
",
    "
",
    "# Initialize lemmatizer and stopwords
",
    "lemmatizer = WordNetLemmatizer()
",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):
",
    "    """
",
    "    Preprocess text by cleaning, tokenizing, removing stopwords, and lemmatizing.
",
    "    
",
    "    Parameters:
",
    "    text (str): Input text to preprocess
",
    "    
",
    "    Returns:
",
    "    str: Preprocessed text
",
    "    """
",
    "    # Convert to lowercase
",
    "    text = text.lower()
",
    "    
",
    "    # Remove HTML tags
",
    "    text = re.sub(r'<.*?>', '', text)
",
    "    
",
    "    # Remove non-alphabetic characters
",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)
",
    "    
",
    "    # Tokenize text
",
    "    tokens = word_tokenize(text)
",
    "    
",
    "    # Remove stopwords
",
    "    tokens = [token for token in tokens if token not in stop_words]
",
    "    
",
    "    # Lemmatize tokens
",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]
",
    "    
",
    "    # Join tokens back into text
",
    "    preprocessed_text = ' '.join(tokens)
",
    "    
",
    "    return preprocessed_text
",
    "
",
    "# Apply preprocessing to a sample of reviews
",
    "sample_size = 1000  # Adjust based on your dataset size and processing power
",
    "df_sample = df_binary.sample(sample_size, random_state=42)
",
    "
",
    "# Preprocess the text
",
    "df_sample['processed_text'] = df_sample['Text'].apply(preprocess_text)
",
    "
",
    "# Display original and preprocessed text
",
    "for i in range(5):
",
    "    print(f"Original: {df_sample.iloc[i]['Text']}")
",
    "    print(f"Processed: {df_sample.iloc[i]['processed_text']}")
",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data for model training
",
    "output_path = '../data/processed_reviews.csv'
",
    "df_binary.to_csv(output_path, index=False)
",
    "print(f"Processed data saved to {output_path}")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
