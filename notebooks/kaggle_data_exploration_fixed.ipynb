{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Sentiment Analysis - Data Exploration\n",
    "\n",
    "This notebook explores the Amazon review dataset from Kaggle to understand its characteristics and prepare it for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Set style for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your data file\n",
    "data_path = '../data/train.csv'\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rating distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "rating_counts = df['Score'].value_counts().sort_index()\n",
    "sns.barplot(x=rating_counts.index, y=rating_counts.values)\n",
    "plt.title('Distribution of Ratings', fontsize=16)\n",
    "plt.xlabel('Rating', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, count in enumerate(rating_counts.values):\n",
    "    plt.text(i, count + 0.1 * max(rating_counts.values), str(count), \n",
    "             ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length\n",
    "df['text_length'] = df['Text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Plot text length distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['text_length'], bins=50, kde=True)\n",
    "plt.title('Distribution of Review Text Length', fontsize=16)\n",
    "plt.xlabel('Text Length (Number of Words)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.xlim(0, 500)  # Limit x-axis for better visualization\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud for All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reviews\n",
    "all_text = ' '.join(df['Text'].dropna().astype(str))\n",
    "\n",
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=800, height=600, background_color='white',\n",
    "                      max_words=100, contour_width=3, \n",
    "                      contour_color='steelblue').generate(all_text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of All Reviews', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for different ratings\n",
    "ratings = sorted(df['Score'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, rating in enumerate(ratings):\n",
    "    # Filter reviews by rating\n",
    "    rating_text = ' '.join(df[df['Score'] == rating]['Text'].dropna().astype(str))\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=600, height=400, background_color='white',\n",
    "                          max_words=50, contour_width=2, \n",
    "                          contour_color='steelblue').generate(rating_text)\n",
    "    \n",
    "    # Display the word cloud\n",
    "    axes[i].imshow(wordcloud, interpolation='bilinear')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(f'Rating {rating} Stars', fontsize=14)\n",
    "\n",
    "# Hide the last subplot if there are less than 6 ratings\n",
    "if len(ratings) < 6:\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and count words\n",
    "all_words = ' '.join(df['Text'].dropna().astype(str)).lower().split()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Get most common words\n",
    "most_common_words = word_counts.most_common(20)\n",
    "\n",
    "# Create dataframe for plotting\n",
    "df_words = pd.DataFrame(most_common_words, columns=['Word', 'Count'])\n",
    "\n",
    "# Plot most common words\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Count', y='Word', data=df_words)\n",
    "plt.title('Most Common Words in Reviews', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Word', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment labels based on rating\n",
    "# 1-2 stars: Negative, 3 stars: Neutral, 4-5 stars: Positive\n",
    "df['sentiment'] = df['Score'].apply(\n",
    "    lambda x: 'negative' if x <= 2 else ('neutral' if x == 3 else 'positive')\n",
    ")\n",
    "\n",
    "# Filter out neutral reviews for binary classification\n",
    "df_binary = df[df['sentiment'] != 'neutral'].copy()\n",
    "\n",
    "# Convert sentiment to binary (0 for negative, 1 for positive)\n",
    "df_binary['sentiment_binary'] = df_binary['sentiment'].apply(\n",
    "    lambda x: 0 if x == 'negative' else 1\n",
    ")\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Binary sentiment dataset shape: {df_binary.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sentiment_counts = df_binary['sentiment'].value_counts()\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)\n",
    "plt.title('Distribution of Sentiments', fontsize=16)\n",
    "plt.xlabel('Sentiment', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# Add count labels on bars\n",
    "for i, count in enumerate(sentiment_counts.values):\n",
    "    plt.text(i, count + 0.1 * max(sentiment_counts.values), str(count), \n",
    "             ha='center', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab of rating and sentiment\n",
    "rating_sentiment = pd.crosstab(df_binary['Score'], df_binary['sentiment'])\n",
    "\n",
    "# Normalize to get proportions\n",
    "rating_sentiment_prop = rating_sentiment.div(rating_sentiment.sum(axis=1), axis=0)\n",
    "\n",
    "# Plot stacked bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "rating_sentiment_prop.plot(kind='bar', stacked=True, color=['#FF9999', '#66B2FF'])\n",
    "plt.title('Sentiment Distribution by Rating', fontsize=16)\n",
    "plt.xlabel('Rating', fontsize=12)\n",
    "plt.ylabel('Proportion', fontsize=12)\n",
    "plt.legend(title='Sentiment')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for positive and negative reviews\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Positive reviews word cloud\n",
    "positive_text = ' '.join(df_binary[df_binary['sentiment'] == 'positive']['Text'].dropna().astype(str))\n",
    "positive_wordcloud = WordCloud(width=600, height=400, background_color='white',\n",
    "                              max_words=100, contour_width=2, \n",
    "                              contour_color='steelblue').generate(positive_text)\n",
    "\n",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')\n",
    "axes[0].axis('off')\n",
    "axes[0].set_title('Positive Reviews', fontsize=16)\n",
    "\n",
    "# Negative reviews word cloud\n",
    "negative_text = ' '.join(df_binary[df_binary['sentiment'] == 'negative']['Text'].dropna().astype(str))\n",
    "negative_wordcloud = WordCloud(width=600, height=400, background_color='white',\n",
    "                              max_words=100, contour_width=2, \n",
    "                              contour_color='steelblue').generate(negative_text)\n",
    "\n",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')\n",
    "axes[1].axis('off')\n",
    "axes[1].set_title('Negative Reviews', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK for text preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources if needed\n",
    "try:\n",
    "    stopwords.words('english')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize NLTK tools\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Remove non-alphabetic characters and convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()\n",
    "    \n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to a sample of reviews\n",
    "sample_size = 1000\n",
    "df_sample = df_binary.sample(sample_size, random_state=42)\n",
    "df_sample['Text_processed'] = df_sample['Text'].apply(preprocess_text)\n",
    "\n",
    "# Display original and processed text\n",
    "for i in range(5):\n",
    "    print(f\"Original: {df_sample.iloc[i]['Text']}\")\n",
    "    print(f\"Processed: {df_sample.iloc[i]['Text_processed']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data for model training\n",
    "df_sample.to_csv('../data/processed_reviews.csv', index=False)\n",
    "print(f\"Processed data saved to ../data/processed_reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}