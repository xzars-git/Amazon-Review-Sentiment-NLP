{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Review Sentiment Analysis - Data Exploration
",
    "
",
    "This notebook explores the Amazon review dataset to understand its characteristics and prepare it for sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd
",
    "import numpy as np
",
    "import matplotlib.pyplot as plt
",
    "import seaborn as sns
",
    "from wordcloud import WordCloud
",
    "import re
",
    "from collections import Counter
",
    "
",
    "# Set style for plots
",
    "sns.set(style="whitegrid")
",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this path to your data file
",
    "data_path = '../data/amazon_reviews.csv'
",
    "
",
    "# Load the data
",
    "try:
",
    "    df = pd.read_csv(data_path)
",
    "    print(f"Data loaded successfully! Shape: {df.shape}")
",
    "except Exception as e:
",
    "    print(f"Error loading data: {e}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows
",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe
",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics
",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values
",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot rating distribution
",
    "plt.figure(figsize=(10, 6))
",
    "rating_counts = df['overall'].value_counts().sort_index()
",
    "sns.barplot(x=rating_counts.index, y=rating_counts.values)
",
    "plt.title('Distribution of Ratings', fontsize=16)
",
    "plt.xlabel('Rating', fontsize=12)
",
    "plt.ylabel('Count', fontsize=12)
",
    "
",
    "# Add count labels on bars
",
    "for i, count in enumerate(rating_counts.values):
",
    "    plt.text(i, count + 0.1 * max(rating_counts.values), str(count), 
",
    "             ha='center', fontsize=12)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length
",
    "df['text_length'] = df['reviewText'].apply(lambda x: len(str(x).split()))
",
    "
",
    "# Plot text length distribution
",
    "plt.figure(figsize=(10, 6))
",
    "sns.histplot(df['text_length'], bins=50, kde=True)
",
    "plt.title('Distribution of Review Text Length', fontsize=16)
",
    "plt.xlabel('Text Length (Number of Words)', fontsize=12)
",
    "plt.ylabel('Frequency', fontsize=12)
",
    "plt.xlim(0, 500)  # Limit x-axis for better visualization
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Cloud for All Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all reviews
",
    "all_text = ' '.join(df['reviewText'].dropna().astype(str))
",
    "
",
    "# Generate word cloud
",
    "wordcloud = WordCloud(width=800, height=600, background_color='white',
",
    "                      max_words=100, contour_width=3, 
",
    "                      contour_color='steelblue').generate(all_text)
",
    "
",
    "# Display the word cloud
",
    "plt.figure(figsize=(12, 8))
",
    "plt.imshow(wordcloud, interpolation='bilinear')
",
    "plt.axis('off')
",
    "plt.title('Word Cloud of All Reviews', fontsize=16)
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for different ratings
",
    "ratings = sorted(df['overall'].unique())
",
    "
",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))
",
    "axes = axes.flatten()
",
    "
",
    "for i, rating in enumerate(ratings):
",
    "    # Filter reviews by rating
",
    "    rating_text = ' '.join(df[df['overall'] == rating]['reviewText'].dropna().astype(str))
",
    "    
",
    "    # Generate word cloud
",
    "    wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                          max_words=50, contour_width=2, 
",
    "                          contour_color='steelblue').generate(rating_text)
",
    "    
",
    "    # Display the word cloud
",
    "    axes[i].imshow(wordcloud, interpolation='bilinear')
",
    "    axes[i].axis('off')
",
    "    axes[i].set_title(f'Rating {rating} Stars', fontsize=14)
",
    "
",
    "# Hide the last subplot if there are less than 6 ratings
",
    "if len(ratings) < 6:
",
    "    axes[-1].axis('off')
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and count words
",
    "all_words = ' '.join(df['reviewText'].dropna().astype(str)).lower().split()
",
    "word_counts = Counter(all_words)
",
    "
",
    "# Get most common words
",
    "most_common_words = word_counts.most_common(20)
",
    "
",
    "# Create dataframe for plotting
",
    "df_words = pd.DataFrame(most_common_words, columns=['Word', 'Count'])
",
    "
",
    "# Plot most common words
",
    "plt.figure(figsize=(12, 8))
",
    "sns.barplot(x='Count', y='Word', data=df_words)
",
    "plt.title('Most Common Words in Reviews', fontsize=16)
",
    "plt.xlabel('Count', fontsize=12)
",
    "plt.ylabel('Word', fontsize=12)
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment labels based on rating
",
    "# 1-2 stars: Negative, 3 stars: Neutral, 4-5 stars: Positive
",
    "df['sentiment'] = df['overall'].apply(
",
    "    lambda x: 'negative' if x <= 2 else ('neutral' if x == 3 else 'positive')
",
    ")
",
    "
",
    "# Filter out neutral reviews for binary classification
",
    "df_binary = df[df['sentiment'] != 'neutral'].copy()
",
    "
",
    "# Convert sentiment to binary (0 for negative, 1 for positive)
",
    "df_binary['sentiment_binary'] = df_binary['sentiment'].apply(
",
    "    lambda x: 0 if x == 'negative' else 1
",
    ")
",
    "
",
    "print(f"Original dataset shape: {df.shape}")
",
    "print(f"Binary sentiment dataset shape: {df_binary.shape}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution
",
    "plt.figure(figsize=(10, 6))
",
    "sentiment_counts = df_binary['sentiment'].value_counts()
",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values)
",
    "plt.title('Distribution of Sentiments', fontsize=16)
",
    "plt.xlabel('Sentiment', fontsize=12)
",
    "plt.ylabel('Count', fontsize=12)
",
    "
",
    "# Add count labels on bars
",
    "for i, count in enumerate(sentiment_counts.values):
",
    "    plt.text(i, count + 0.1 * max(sentiment_counts.values), str(count), 
",
    "             ha='center', fontsize=12)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment by Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a crosstab of rating and sentiment
",
    "rating_sentiment = pd.crosstab(df_binary['overall'], df_binary['sentiment'])
",
    "
",
    "# Normalize to get proportions
",
    "rating_sentiment_prop = rating_sentiment.div(rating_sentiment.sum(axis=1), axis=0)
",
    "
",
    "# Plot stacked bar chart
",
    "plt.figure(figsize=(10, 6))
",
    "rating_sentiment_prop.plot(kind='bar', stacked=True, color=['#FF9999', '#66B2FF'])
",
    "plt.title('Sentiment Distribution by Rating', fontsize=16)
",
    "plt.xlabel('Rating', fontsize=12)
",
    "plt.ylabel('Proportion', fontsize=12)
",
    "plt.legend(title='Sentiment')
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds by Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for positive and negative reviews
",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))
",
    "
",
    "# Positive reviews word cloud
",
    "positive_text = ' '.join(df_binary[df_binary['sentiment'] == 'positive']['reviewText'].dropna().astype(str))
",
    "positive_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(positive_text)
",
    "
",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')
",
    "axes[0].axis('off')
",
    "axes[0].set_title('Positive Reviews', fontsize=16)
",
    "
",
    "# Negative reviews word cloud
",
    "negative_text = ' '.join(df_binary[df_binary['sentiment'] == 'negative']['reviewText'].dropna().astype(str))
",
    "negative_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(negative_text)
",
    "
",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')
",
    "axes[1].axis('off')
",
    "axes[1].set_title('Negative Reviews', fontsize=16)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLTK for text preprocessing
",
    "import nltk
",
    "from nltk.corpus import stopwords
",
    "from nltk.stem import WordNetLemmatizer
",
    "from nltk.tokenize import word_tokenize
",
    "
",
    "# Download NLTK resources if needed
",
    "try:
",
    "    stopwords.words('english')
",
    "except LookupError:
",
    "    nltk.download('stopwords')
",
    "
",
    "try:
",
    "    nltk.data.find('tokenizers/punkt')
",
    "except LookupError:
",
    "    nltk.download('punkt')
",
    "
",
    "try:
",
    "    nltk.data.find('corpora/wordnet')
",
    "except LookupError:
",
    "    nltk.download('wordnet')
",
    "
",
    "# Initialize lemmatizer and stopwords
",
    "lemmatizer = WordNetLemmatizer()
",
    "stop_words = set(stopwords.words('english'))
",
    "
",
    "def preprocess_text(text):
",
    "    """
",
    "    Clean and preprocess text data.
",
    "    """
",
    "    # Remove HTML tags
",
    "    text = re.sub(r'<.*?>', '', text)
",
    "    
",
    "    # Remove non-alphabetic characters and convert to lowercase
",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower()
",
    "    
",
    "    # Tokenize text
",
    "    tokens = word_tokenize(text)
",
    "    
",
    "    # Remove stopwords
",
    "    tokens = [token for token in tokens if token not in stop_words]
",
    "    
",
    "    # Lemmatize tokens
",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]
",
    "    
",
    "    # Join tokens back into text
",
    "    text = ' '.join(tokens)
",
    "    
",
    "    return text
",
    "
",
    "# Apply preprocessing to a sample of reviews
",
    "sample_size = 1000
",
    "df_sample = df_binary.sample(min(sample_size, len(df_binary)), random_state=42).copy()
",
    "df_sample['processed_text'] = df_sample['reviewText'].apply(preprocess_text)
",
    "
",
    "# Display original and processed text for a few examples
",
    "for i in range(5):
",
    "    print(f"Original: {df_sample.iloc[i]['reviewText'][:200]}...")
",
    "    print(f"Processed: {df_sample.iloc[i]['processed_text'][:200]}...")
",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds of Processed Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for processed positive and negative reviews
",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))
",
    "
",
    "# Positive reviews word cloud
",
    "positive_processed_text = ' '.join(df_sample[df_sample['sentiment'] == 'positive']['processed_text'])
",
    "positive_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(positive_processed_text)
",
    "
",
    "axes[0].imshow(positive_wordcloud, interpolation='bilinear')
",
    "axes[0].axis('off')
",
    "axes[0].set_title('Positive Reviews (Processed)', fontsize=16)
",
    "
",
    "# Negative reviews word cloud
",
    "negative_processed_text = ' '.join(df_sample[df_sample['sentiment'] == 'negative']['processed_text'])
",
    "negative_wordcloud = WordCloud(width=600, height=400, background_color='white',
",
    "                              max_words=100, contour_width=2, 
",
    "                              contour_color='steelblue').generate(negative_processed_text)
",
    "
",
    "axes[1].imshow(negative_wordcloud, interpolation='bilinear')
",
    "axes[1].axis('off')
",
    "axes[1].set_title('Negative Reviews (Processed)', fontsize=16)
",
    "
",
    "plt.tight_layout()
",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps
",
    "
",
    "From this exploration, we've learned:
",
    "
",
    "1. The dataset contains reviews with ratings from 1 to 5 stars.
",
    "2. We've created binary sentiment labels (positive/negative) based on ratings.
",
    "3. There are distinct patterns in words used in positive vs. negative reviews.
",
    "4. Text preprocessing helps to clean the text and focus on meaningful words.
",
    "
",
    "Next steps for building a sentiment analysis model:
",
    "
",
    "1. Apply text preprocessing to the entire dataset.
",
    "2. Split the data into training and testing sets.
",
    "3. Vectorize the text data (e.g., using TF-IDF).
",
    "4. Train different classification models.
",
    "5. Evaluate model performance.
",
    "6. Select the best model for deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
